{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"迴歸分析實例\"\n",
        "description: \"\"\n",
        "date: \"2025-07-31\"\n",
        "jupyter: python3\n",
        "execute:\n",
        "    echo: false  # 是否顯示代碼\n",
        "format:\n",
        "  html:\n",
        "    code-fold: true\n",
        "    code-summary: \"顯示／隱藏程式碼\"\n",
        "    code-tools: true\n",
        "---"
      ],
      "id": "efbb9e0b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 下載套件\n",
        "# !python -m pip install scikit-learn\n",
        "# 載入套件\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import Markdown\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import seaborn as sns       \n",
        "\n",
        "# 設定中文字體\n",
        "plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'SimHei', 'Arial Unicode MS']\n",
        "plt.rcParams['axes.unicode_minus'] = False  # 解決負號顯示問題"
      ],
      "id": "e8271932",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 範例一：線性迴歸概念及scikit-learn 實作\n",
        "\n",
        "以動物體重與奔跑速度作為範例，使用 比較公式計算與scikit-learn 實作的結果\n",
        "\n",
        "::: {.columns}\n",
        "\n",
        "::: {.column style=\"width:45%; padding-right: 2rem;\"}\n",
        "\n",
        "### 資料\n"
      ],
      "id": "52baec90"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 輸入資料\n",
        "raw_data_lm = [\n",
        "    (\"犀牛\", 1400, 45),\n",
        "    (\"馬\", 400, 70),\n",
        "    (\"羚羊\", 50, 100),\n",
        "    (\"長頸鹿\", 1000, 60),\n",
        "    (\"斑馬\", 300, 90),\n",
        "    (\"獵豹\", 60, 110),\n",
        "]\n",
        "\n",
        "# 轉為 DataFrame\n",
        "df_lm = pd.DataFrame(raw_data_lm, columns=['動物', '動物體重 (kg)', '最大奔跑速度 (km/h)'])\n",
        "\n",
        "Markdown(df_lm.to_markdown(index=False))"
      ],
      "id": "699d2499",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {.column style=\"width:55%; margin-left: auto; margin-right: 0;\"}\n",
        "\n",
        "### 散點圖\n"
      ],
      "id": "843c9623"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-width": 4,
        "fig-height": 3,
        "fig-format": "svg"
      },
      "source": [
        "#| fig-align: center\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure(figsize=(4, 3))\n",
        "plt.scatter(df_lm[\"動物體重 (kg)\"], df_lm[\"最大奔跑速度 (km/h)\"])\n",
        "plt.xlabel(\"動物體重 (kg)\")\n",
        "plt.ylabel(\"最大奔跑速度 (km/h)\")\n",
        "plt.title(\"動物體重與最大奔跑速度之間的散點圖\")\n",
        "# 在每個散點旁標註座標\n",
        "ax = plt.gca()\n",
        "for x, y in zip(df_lm[\"動物體重 (kg)\"].values, df_lm[\"最大奔跑速度 (km/h)\"].values):\n",
        "    ax.annotate(f\"({x:.0f}, {y:.0f})\", (x, y),\n",
        "        textcoords=\"offset points\", xytext=(5, 5), fontsize=8)\n",
        "plt.show()"
      ],
      "id": "572a07d6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "### 公式計算\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\hat{{\\mathbf{\\beta}}} = (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{y}\n",
        "\\end{align}\n",
        "$$\n"
      ],
      "id": "8d43c6c9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | echo: true\n",
        "\n",
        "# 依照公式 \\hat{beta} = (X^T X)^{-1} X^T y 計算參數\n",
        "X_raw = df_lm[\"動物體重 (kg)\"].to_numpy(dtype=float)\n",
        "y_vec = df_lm[\"最大奔跑速度 (km/h)\"].to_numpy(dtype=float)\n",
        "\n",
        "# 設計矩陣：第一欄為截距(常數1)，第二欄為特徵 X\n",
        "X_design = np.column_stack([np.ones(len(X_raw)), X_raw])\n",
        "\n",
        "# 依公式計算參數向量 [a, b]\n",
        "beta_hat = np.linalg.inv(X_design.T @ X_design) @ (X_design.T @ y_vec)\n",
        "a, b = float(beta_hat[0]), float(beta_hat[1])\n",
        "\n",
        "print(f\"公式計算得出的迴歸模型: y={b:.3f}x+{a:.3f}\")"
      ],
      "id": "d9873fd5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### scikit-learn 建立迴歸模型\n"
      ],
      "id": "16d0a31d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | echo: true\n",
        "# 建立迴歸模型\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 特徵與目標（注意特徵需為 2D）\n",
        "features_X = df_lm[[\"動物體重 (kg)\"]].values\n",
        "target_y = df_lm[\"最大奔跑速度 (km/h)\"].values\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "# 訓練模型\n",
        "model.fit(features_X, target_y)\n",
        "\n",
        "print(f\"scikit-learn 計算得出的迴歸模型: y={model.coef_[0].round(3)}x+{model.intercept_.round(3)}\")"
      ],
      "id": "546baa08",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 畫出散佈圖\n",
        "plt.scatter(features_X.flatten(), target_y, label=\"原始資料點\")\n",
        "\n",
        "# 畫出回歸線\n",
        "x_range = np.linspace(features_X.min(), features_X.max(), 100).reshape(-1, 1)\n",
        "y_pred = model.predict(x_range)\n",
        "plt.plot(x_range, y_pred, label=\"線性迴歸線\", linestyle=\"--\")\n",
        "\n",
        "# 垂直於回歸線的距離（幾何最短距離）\n",
        "ax = plt.gca()\n",
        "m = float(np.ravel(model.coef_)[0])\n",
        "b0 = float(np.ravel(model.intercept_))\n",
        "for x, y in zip(features_X.ravel(), target_y.ravel()):\n",
        "    xp = (x + m * (y - b0)) / (m * m + 1)\n",
        "    yp = m * xp + b0\n",
        "    ax.plot([x, xp], [y, yp], color=\"purple\", linestyle=\"--\", linewidth=1)\n",
        "    d = abs(m * x - y + b0) / np.sqrt(m * m + 1)\n",
        "    ax.annotate(\n",
        "        f\"{d:.2f}\",\n",
        "        ((x + xp) / 2, (y + yp) / 2),\n",
        "        textcoords=\"offset points\",\n",
        "        xytext=(5, 0),\n",
        "        color=\"purple\",\n",
        "        fontsize=8,\n",
        "    )\n",
        "\n",
        "plt.xlabel(\"動物體重 (kg)\")\n",
        "plt.ylabel(\"最大奔跑速度 (km/h)\")\n",
        "plt.title(\"動物體重與奔跑速度的線性回歸\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "id": "bfab7c06",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 預測\n"
      ],
      "id": "8e3b3aae"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | echo: true\n",
        "# 預測\n",
        "x = 1000\n",
        "sklearn_y = model.predict([[x]])\n",
        "formula_y = a + b * x\n",
        "\n",
        "print(f\"預測 {x}kg 的動物最大奔跑速度，scikit-learn 預測值為 {sklearn_y[0].round(3)} km/h，公式計算得出的預測值為 {formula_y:.3f} km/h\")"
      ],
      "id": "54b18351",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "可知，scikit-learn 與公式計算得出的預測值相同，原因是 scikit-learn 在背後也是使用公式計算的。\n",
        "\n",
        "## 範例二：邏輯迴歸與線性迴歸的比較\n",
        "\n",
        "假設我們想預測學生是否會及格，資料如下，X軸代表每日學習時數，Y軸代表是否及格\n",
        "\n",
        "::: {.columns}\n",
        "\n",
        "::: {.column style=\"width:45%; padding-right: 2rem;\"}\n",
        "\n",
        "\n",
        "### 資料\n"
      ],
      "id": "5febc920"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 1. 定義資料（學習時數 X 和 是否及格 Y）\n",
        "raw_data = [(\"A\", 1, 0), \n",
        "    (\"B\", 2, 1), \n",
        "    (\"C\", 3, 0), \n",
        "    (\"D\", 5, 0), \n",
        "    (\"E\", 5, 1),\n",
        "    (\"F\", 8, 1),\n",
        "    (\"G\", 8, 1),\n",
        "    (\"H\", 8, 0),\n",
        "    (\"I\", 9, 1),\n",
        "    (\"J\", 10, 1),\n",
        "    ]\n",
        "\n",
        "# 轉為 DataFrame\n",
        "logistic_df = pd.DataFrame(raw_data, columns=[\"學生\", \"學習時數\", \"是否及格\"])\n",
        "\n",
        "Markdown(logistic_df.to_markdown(index=False))"
      ],
      "id": "fcf052a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {.column style=\"width:55%; margin-left: auto; margin-right: 0;\"}\n",
        "\n",
        "### 散點圖\n"
      ],
      "id": "47ccd23c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.style.use(\"ggplot\")\n",
        "plt.figure(figsize=(4, 3))\n",
        "plt.scatter(logistic_df[\"學習時數\"], logistic_df[\"是否及格\"])\n",
        "plt.xlabel(\"學習時數\")\n",
        "plt.ylabel(\"是否及格\")\n",
        "plt.title(\"學習時數與是否及格之間的散點圖\")\n",
        "plt.show()"
      ],
      "id": "f0a22bb9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "上方的資料可以明顯看出，Y軸的值屬於二元變數，是離散型的。從散點圖中可以看出，學習時數與是否及格之間的關係並非線性。\n",
        "\n",
        "使用 scikit-learn 取得模型參數，並畫出 sigmoid 曲線，紅色點為原始資料，藍色點為經過 sigmoid 函數轉換後的值，藍色線為根據原始資料所作的線性迴歸，紅色線為 sigmoid 曲線。\n"
      ],
      "id": "d144dc4a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | echo: true\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "\n",
        "X = logistic_df[[\"學習時數\"]].values  # 特徵（輸入）\n",
        "Y = logistic_df[\"是否及格\"].values  # 標籤（目標）\n",
        "\n",
        "\n",
        "# 2. 建立並訓練邏輯回歸模型\n",
        "model = LogisticRegression()\n",
        "model.fit(X, Y)\n",
        "\n",
        "# 3. 取得模型參數（截距和斜率）\n",
        "beta_0 = model.intercept_[0]\n",
        "beta_1 = model.coef_[0][0]\n",
        "\n",
        "print(f\"σ(z)模型參數：beta_0 = {beta_0:.4f}, beta_1 = {beta_1:.4f}\")\n",
        "\n",
        "\n",
        "# 4. 計算每個 X 對應的 z 和 sigmoid(z)\n",
        "z = beta_0 + beta_1 * X.flatten()\n",
        "\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "\n",
        "predicted_probabilities = sigmoid(z)\n",
        "\n",
        "# 顯示每筆資料的 z 與預測機率\n",
        "for i in range(len(X)):\n",
        "    print(f\"X = {X[i][0]}, z = {z[i]:.4f}, σ(z) = {predicted_probabilities[i]:.4f}\")\n",
        "\n",
        "# 5. 畫 sigmoid 曲線\n",
        "x_min, x_max = X.min() - 3, X.max() + 3\n",
        "x_range = np.linspace(x_min, x_max, 300)\n",
        "z_range = beta_0 + beta_1 * x_range\n",
        "sigmoid_curve = sigmoid(z_range)\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure(figsize=(7, 4))\n",
        "plt.plot(x_range, sigmoid_curve, label=\"Sigmoid Curve\", linewidth=2)\n",
        "\n",
        "# 線性迴歸\n",
        "lin_model = LinearRegression()\n",
        "lin_model.fit(X, Y)\n",
        "lin_predictions = lin_model.predict(x_range.reshape(-1, 1))\n",
        "plt.plot(x_range, lin_predictions, label=\"線性迴歸\", linestyle=\"--\", linewidth=2)\n",
        "\n",
        "\n",
        "# 資料點\n",
        "plt.scatter(X, Y, color=\"red\", label=\"Original Data (Y)\", zorder=5)\n",
        "plt.scatter(\n",
        "    X,\n",
        "    predicted_probabilities,\n",
        "    color=\"blue\",\n",
        "    label=\"Predicted Probabilities\",\n",
        "    marker=\"x\",\n",
        "    zorder=5,\n",
        ")\n",
        "plt.axhline(0.5, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
        "plt.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
        "plt.axhline(1, color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
        "plt.xlabel(\"X（學習時數）\")\n",
        "plt.ylabel(\"Y=1 的機率\")\n",
        "plt.title(\"邏輯迴歸：Sigmoid 曲線與機率\")\n",
        "plt.legend(loc=\"upper left\", bbox_to_anchor=(1.02, 1.0))\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "5da95c35",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "s型曲線更能展現出此資料分布的特性，而線性迴歸則無法。並且邏輯迴歸的預測值永遠介於 0~1，代表「Y=1 的機率」，而線性迴歸的預測值可以小於 0 或大於 1，沒有機率意義。\n",
        "\n",
        "### 預測\n"
      ],
      "id": "fb9d4463"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | echo: true\n",
        "# 預測\n",
        "x_new = np.array([[0], [3],[4.5], [6], [15]])\n",
        "y_logistic = model.predict_proba(x_new)[:, 1]\n",
        "y_linear = lin_model.predict(x_new)\n",
        "\n",
        "# 建立 DataFrame 表格\n",
        "df_pred = pd.DataFrame(\n",
        "    {\n",
        "        \"學習時數\": x_new.flatten(),\n",
        "        \"邏輯回歸預測機率 (P=1)\": y_logistic.round(3),\n",
        "        \"線性回歸預測值\": y_linear.round(3),\n",
        "    }\n",
        ")\n",
        "\n",
        "# 顯示表格\n",
        "Markdown(df_pred.to_markdown(index=False))"
      ],
      "id": "53108878",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **邏輯回歸預測值**：永遠介於 0~1，代表「Y=1 的機率」\n",
        "- **線性回歸預測值**：可以小於 0 或大於 1，沒有機率意義\n",
        "\n",
        "## 範例三：kaggle 5050 家新創企業數據，線性迴歸的實際應用\n",
        "\n",
        "資料來源：https://www.kaggle.com/datasets/amineoumous/50-startups-data\n",
        "\n",
        "資料內容：50 家新創企業的資料，包括 「研發支出」、「管理」、「行銷支出」、「所在州」、「利潤」。前 3 列表示每家新創公司在研發、行銷和管理方面的支出；所在州列表示新創公司位於哪個州；最後一列表示新創公司的利潤。\n",
        "\n",
        "### 資料概述\n"
      ],
      "id": "9e99d8b4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 載入資料\n",
        "startups_df = pd.read_csv(\"50_Startups.csv\")\n",
        "# 筆數、欄位數\n",
        "print(f\"筆數：{startups_df.shape[0]}，欄位數：{startups_df.shape[1]}\")\n",
        "\n",
        "# 欄位名稱與資料型態\n",
        "print(startups_df.dtypes)\n",
        "\n",
        "# 資料概述\n",
        "print(startups_df.describe())\n",
        "\n",
        "# 類別資料統計\n",
        "print(startups_df[\"State\"].value_counts())"
      ],
      "id": "25b41fa1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 探索分析(Exploratory Data Analysis, EDA)\n"
      ],
      "id": "88cfaff0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | echo: true\n",
        "\n",
        "\n",
        "# Profit 分布\n",
        "plt.figure(figsize=(7, 4))\n",
        "sns.histplot(startups_df[\"Profit\"], bins=30, kde=True)\n",
        "plt.title(\"Profit 分布\")\n",
        "plt.show()\n",
        "\n",
        "# 各支出與 Profit 的關係（散點圖 + 相關係數熱力圖）\n",
        "fig, axes = plt.subplots(2, 2, figsize=(7, 4))\n",
        "\n",
        "# R&D Spend vs Profit\n",
        "sns.scatterplot(ax=axes[0, 0], x=\"R&D Spend\", y=\"Profit\", data=startups_df)\n",
        "axes[0, 0].set_title(\"R&D Spend 與 Profit 的關係\")\n",
        "\n",
        "# Marketing Spend vs Profit\n",
        "sns.scatterplot(ax=axes[0, 1], x=\"Marketing Spend\", y=\"Profit\", data=startups_df)\n",
        "axes[0, 1].set_title(\"Marketing Spend 與 Profit 的關係\")\n",
        "\n",
        "# Administration vs Profit\n",
        "sns.scatterplot(ax=axes[1, 0], x=\"Administration\", y=\"Profit\", data=startups_df)\n",
        "axes[1, 0].set_title(\"Administration 與 Profit 的關係\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 相關係數熱力圖\n",
        "sns.heatmap(startups_df.corr(), annot=True, cmap=\"coolwarm\", linewidths=0.5)\n",
        "\n",
        "# 初步觀察的趨勢（哪些支出可能影響大）"
      ],
      "id": "4a80050d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "可以看出，R&D Spend 與 Profit 的關係最強，Marketing Spend 與 Profit 的關係最弱。\n",
        "\n",
        "### 模型分析    \n"
      ],
      "id": "53d24354"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | echo: true\n",
        "# 方法：多元線性迴歸（OLS）\n",
        "\n",
        "# 重要變數：影響大小 + 顯著性（可用顯著性標記圖）\n",
        "\n",
        "# 模型評估（R²、調整後 R²、RMSE）"
      ],
      "id": "3788a4d5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 結論與建議\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## 範例四:邏輯迴歸的實際應用\n"
      ],
      "id": "a746b62c"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\226169\\AppData\\Local\\Programs\\Python\\Python312\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}